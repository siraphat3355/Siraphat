{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02ee9c3a-6deb-4675-96df-84f91f5303db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "import pickle\n",
    "import pendulum\n",
    "import requests\n",
    "import json\n",
    "import threading\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "from azure.cosmos import CosmosClient\n",
    "import time\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "from inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType\n",
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10795bda-bf1c-4a57-911f-ffa98927fc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = joblib.load('model.pkl')\n",
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3c5ca7-ac30-4502-b9f7-bd7c61ca75d7",
   "metadata": {},
   "source": [
    "### Import model from Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "137c654c-37b7-4851-90e5-f39c8b22a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_str = 'DefaultEndpointsProtocol=https;AccountName=joblove;AccountKey=6vRDCWJb8CfB1FAPvnUlubd4Kcxa75Mtut38aja0R2u293V/JucMzw72lR1aslcJwr2EYQWtlO4ybSAzd4K8fA==;EndpointSuffix=core.windows.net'\n",
    "container_name = 'joblove'\n",
    "azure_target_path = \"model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c438cad6-9fc2-47fd-91be-d2648e122de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_client = BlobClient.from_connection_string(connection_str, container_name,azure_target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22a0a3b0-d0f6-4efd-a63e-0430ddbcea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = blob_client.download_blob().readall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c1a2863-3cfb-422e-b6c1-418397357d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ForecastingPipelineWrapper(pipeline=Pipeline(memory=None,\n",
       "                                             steps=[('timeseriestransformer',\n",
       "                                                     TimeSeriesTransformer(featurization_config=None,\n",
       "                                                                           pipeline_type=<TimeSeriesPipelineType.FULL: 1>)),\n",
       "                                                    ('prefittedsoftvotingregressor',\n",
       "                                                     PreFittedSoftVotingRegressor(estimators=[('7',\n",
       "                                                                                               Pipeline(memory=None,\n",
       "                                                                                                        steps=[('standardscalerwrapper',\n",
       "                                                                                                                <azureml.automl.runtime.shared.mod...\n",
       "                                                                                                                ElasticNet(alpha=0.05357894736842105,\n",
       "                                                                                                                           copy_X=True,\n",
       "                                                                                                                           fit_intercept=True,\n",
       "                                                                                                                           l1_ratio=0.6352631578947369,\n",
       "                                                                                                                           max_iter=1000,\n",
       "                                                                                                                           normalize=False,\n",
       "                                                                                                                           positive=False,\n",
       "                                                                                                                           precompute=False,\n",
       "                                                                                                                           random_state=None,\n",
       "                                                                                                                           selection='cyclic',\n",
       "                                                                                                                           tol=0.0001,\n",
       "                                                                                                                           warm_start=False))],\n",
       "                                                                                                        verbose=False))],\n",
       "                                                                                  weights=[0.3333333333333333,\n",
       "                                                                                           0.26666666666666666,\n",
       "                                                                                           0.26666666666666666,\n",
       "                                                                                           0.06666666666666667,\n",
       "                                                                                           0.06666666666666667]))],\n",
       "                                             verbose=False),\n",
       "                           stddev=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pickle.loads(x)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d15498e5-e892-41b4-aeae-ed665ad2ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.forecast()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d62385-9cc2-449a-82ce-3e84488a0b1f",
   "metadata": {},
   "source": [
    "### Query Power data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "756cae09-812e-447c-aa04-91e21e88ab8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ContainerProxy [dbs/altonucminteldb/colls/iotcontainer]>\n",
      "Query time [second]: 152.001\n",
      "finish get dataset from cosmosdb function\n"
     ]
    }
   ],
   "source": [
    "# CosmosDB\n",
    "cosmos_url = \"https://altocosmos.documents.azure.com:443/\"\n",
    "cosmos_key = \"W6BRohNWpaaOFAyFMxW5NPGuHCDUHTNwQwXDVOyvMeDxLEtKBE8oF62GoWH2j4xUa3td5jIh6ljt8EVf5lmNdw==\"\n",
    "client = CosmosClient(cosmos_url, credential=cosmos_key)\n",
    "database_name = 'altonucminteldb'\n",
    "database = client.get_database_client(database_name)\n",
    "container_name = 'iotcontainer'\n",
    "container = database.get_container_client(container_name)\n",
    "print(container)\n",
    "\n",
    "def get_dataset_from_cosmosdb():\n",
    "    # Get dataset from cosmosdb\n",
    "    try:\n",
    "        last_day_of_last_month_date = pendulum.now('Asia/Bangkok').subtract(months=1).end_of('month').to_date_string()\n",
    "        first_day_of_next_month_date = pendulum.now('Asia/Bangkok').add(months=1).start_of('month').to_date_string()\n",
    "        query_string = f\"SELECT c.timestamp, c.device_id, c.subdevice_idx, c.location, c.subdevice_name, \\\n",
    "        c.power, c.gatewayid FROM c WHERE c.gatewayid='altonucmintelmonitor' AND c.location='main_energy/iot_devices' \\\n",
    "        AND c.subdevice_name='total' AND c.timestamp >= '2021-06-01' \\\n",
    "        AND c.timestamp < '{first_day_of_next_month_date}' \\\n",
    "        ORDER BY c.timestamp ASC\"\n",
    "        time1 = time.time()\n",
    "        results = []\n",
    "\n",
    "        try:\n",
    "            for item in container.query_items(\n",
    "                    query=query_string,\n",
    "                    enable_cross_partition_query=True):\n",
    "                #print(json.dumps(item, indent=True)) \n",
    "                results.append(item)\n",
    "        except Exception as e:\n",
    "            print(\"no data\")\n",
    "            print(e)\n",
    "\n",
    "        print(f\"Query time [second]: {time.time() - time1:.3f}\")\n",
    "        df = pd.DataFrame(results)\n",
    "        print(\"finish get dataset from cosmosdb function\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] get dataset from cosmosdb function: {e}\")\n",
    "\n",
    "dfe = get_dataset_from_cosmosdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a5cf4b0-bd5e-4750-8d85-799192563fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elec_dataprep(df):\n",
    "    df['datetime'] = df['timestamp'].apply(lambda x: pendulum.parse(x).add(hours=7).to_datetime_string())\n",
    "    df.loc[:, 'datetime'] = pd.to_datetime(df.loc[:, 'datetime'])\n",
    "    df = df[['datetime', 'power']]\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    df = df.resample('30min').mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9c0d412-9384-4403-a238-15ebe43be177",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe2 = elec_dataprep(dfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d541b398-de68-44cf-aafa-d31be9ee1fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>power</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-06-01 07:00:00</th>\n",
       "      <td>24.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-01 07:30:00</th>\n",
       "      <td>31.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-01 08:00:00</th>\n",
       "      <td>23.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     power\n",
       "datetime                  \n",
       "2021-06-01 07:00:00  24.28\n",
       "2021-06-01 07:30:00  31.04\n",
       "2021-06-01 08:00:00  23.98"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfe2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be3ae49-a75d-49be-8783-9bf50283f71c",
   "metadata": {},
   "source": [
    "### Query Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "531ab3ca-94ac-4627-b8c3-7d5a4b9a781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outdoor_weather_data():\n",
    "    dt = pendulum.now('Asia/Bangkok')\n",
    "    _valid_time = pendulum.datetime(2021, 2, 1, tz='Asia/Bangkok')\n",
    "    _end_time = pendulum.today('Asia/Bangkok')\n",
    "    Data = {}\n",
    "\n",
    "    def worker(dt):\n",
    "        a = requests.get(\"https://api.weather.com/v1/location/VTBD:9:TH/observations/historical.json?apiKey=6532d6454b8aa370768e63d6ba5a832e&units=e&startDate={}\".format(dt))\n",
    "        b = json.loads(a.text)\n",
    "        c = pd.DataFrame(b[\"observations\"])\n",
    "        Data[dt] = c\n",
    "\n",
    "    num_th = 20\n",
    "    while _end_time > _valid_time:\n",
    "\n",
    "        threads = []        \n",
    "        for i in range(num_th):            \n",
    "            if _end_time <= _valid_time:\n",
    "                break\n",
    "\n",
    "            dt = _valid_time.strftime(\"%Y%m%d\")\n",
    "            t = threading.Thread(target=worker, args=(dt,))\n",
    "            threads.append(t)       \n",
    "            _valid_time = _valid_time.add(days=1)\n",
    "\n",
    "        for t in threads:\n",
    "            t.start()           \n",
    "        for t in threads:\n",
    "            t.join()\n",
    "\n",
    "    df = pd.concat([Data[k] for k in Data], axis=0)\n",
    "\n",
    "    # Remove columns with more than 90% data as null.\n",
    "    cols_to_delete = df.columns[df.isnull().sum()/len(df) > .90]\n",
    "    df.drop(cols_to_delete, axis = 1, inplace = True)\n",
    "\n",
    "    df = df.sort_values(by=\"valid_time_gmt\")\n",
    "\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"valid_time_gmt\"].astype(int)*1e9) + timedelta(hours=7)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.set_index(\"datetime\")\n",
    "\n",
    "    # Drop irrelevant columns\n",
    "    columns = ['key', 'class', 'expire_time_gmt', 'obs_id', 'obs_name']\n",
    "    df.drop(columns=columns, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84809e92-73cb-47c2-af79-d043c9e4cb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valid_time_gmt</th>\n",
       "      <th>day_ind</th>\n",
       "      <th>temp</th>\n",
       "      <th>wx_icon</th>\n",
       "      <th>icon_extd</th>\n",
       "      <th>wx_phrase</th>\n",
       "      <th>dewPt</th>\n",
       "      <th>heat_index</th>\n",
       "      <th>rh</th>\n",
       "      <th>pressure</th>\n",
       "      <th>vis</th>\n",
       "      <th>wc</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wdir_cardinal</th>\n",
       "      <th>wspd</th>\n",
       "      <th>uv_desc</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>uv_index</th>\n",
       "      <th>clds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-01 00:00:00</th>\n",
       "      <td>1612112400</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>33</td>\n",
       "      <td>3300</td>\n",
       "      <td>Fair</td>\n",
       "      <td>68</td>\n",
       "      <td>81</td>\n",
       "      <td>69</td>\n",
       "      <td>29.93</td>\n",
       "      <td>3.00</td>\n",
       "      <td>79</td>\n",
       "      <td>nan</td>\n",
       "      <td>CALM</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>FEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-01 00:30:00</th>\n",
       "      <td>1612114200</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>33</td>\n",
       "      <td>3300</td>\n",
       "      <td>Fair</td>\n",
       "      <td>68</td>\n",
       "      <td>81</td>\n",
       "      <td>69</td>\n",
       "      <td>29.93</td>\n",
       "      <td>3.00</td>\n",
       "      <td>79</td>\n",
       "      <td>nan</td>\n",
       "      <td>CALM</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>FEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-01 01:00:00</th>\n",
       "      <td>1612116000</td>\n",
       "      <td>N</td>\n",
       "      <td>77</td>\n",
       "      <td>33</td>\n",
       "      <td>3300</td>\n",
       "      <td>Fair</td>\n",
       "      <td>68</td>\n",
       "      <td>79</td>\n",
       "      <td>74</td>\n",
       "      <td>29.93</td>\n",
       "      <td>3.00</td>\n",
       "      <td>77</td>\n",
       "      <td>nan</td>\n",
       "      <td>CALM</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>CLR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     valid_time_gmt day_ind  temp  wx_icon  icon_extd  \\\n",
       "datetime                                                                \n",
       "2021-02-01 00:00:00      1612112400       N    79       33       3300   \n",
       "2021-02-01 00:30:00      1612114200       N    79       33       3300   \n",
       "2021-02-01 01:00:00      1612116000       N    77       33       3300   \n",
       "\n",
       "                    wx_phrase  dewPt  heat_index  rh  pressure  vis  wc  wdir  \\\n",
       "datetime                                                                        \n",
       "2021-02-01 00:00:00      Fair     68          81  69     29.93 3.00  79   nan   \n",
       "2021-02-01 00:30:00      Fair     68          81  69     29.93 3.00  79   nan   \n",
       "2021-02-01 01:00:00      Fair     68          79  74     29.93 3.00  77   nan   \n",
       "\n",
       "                    wdir_cardinal  wspd uv_desc  feels_like  uv_index clds  \n",
       "datetime                                                                    \n",
       "2021-02-01 00:00:00          CALM     0     Low          81         0  FEW  \n",
       "2021-02-01 00:30:00          CALM     0     Low          81         0  FEW  \n",
       "2021-02-01 01:00:00          CALM     0     Low          79         0  CLR  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfw = get_outdoor_weather_data()\n",
    "dfw.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8913114a-6144-45eb-898c-dbc32dbbdfbf",
   "metadata": {},
   "source": [
    "### Merge both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a0267e2-8dbd-4b88-978b-dc171db1ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(df1, df2):\n",
    "    df = pd.merge(df1, df2, left_index=True, right_index=True)\n",
    "    columns = ['power', 'temp', 'rh']\n",
    "    \n",
    "    return df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bebda0ef-be18-44f9-9785-e05cdc7b9743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>power</th>\n",
       "      <th>temp</th>\n",
       "      <th>rh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-06-01 07:00:00</th>\n",
       "      <td>24.28</td>\n",
       "      <td>84</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-01 07:30:00</th>\n",
       "      <td>31.04</td>\n",
       "      <td>86</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-01 08:00:00</th>\n",
       "      <td>23.98</td>\n",
       "      <td>88</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     power  temp  rh\n",
       "datetime                            \n",
       "2021-06-01 07:00:00  24.28    84  79\n",
       "2021-06-01 07:30:00  31.04    86  74\n",
       "2021-06-01 08:00:00  23.98    88  70"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff = merge(dfe2, dfw)\n",
    "dff.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312dc39d-a30f-455e-b371-de392f2e818d",
   "metadata": {},
   "source": [
    "### Prepare X_future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "440ec5e7-f060-483b-b46f-c1ea2a41933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def historical_api():\n",
    "\n",
    "    dt = pendulum.now('Asia/Bangkok')\n",
    "    # _valid_time = pendulum.today(tz='Asia/Bangkok')\n",
    "    _valid_time = pendulum.today(tz='Asia/Bangkok')\n",
    "    _end_time = pendulum.tomorrow(tz='Asia/Bangkok')\n",
    "    Data = {}\n",
    "\n",
    "    def worker(dt):\n",
    "        a = requests.get(\"https://api.weather.com/v1/location/VTBD:9:TH/observations/historical.json?apiKey=6532d6454b8aa370768e63d6ba5a832e&units=e&startDate={}\".format(dt))\n",
    "        b = json.loads(a.text)\n",
    "        c = pd.DataFrame(b[\"observations\"])\n",
    "        Data[dt] = c\n",
    "\n",
    "    num_th = 20\n",
    "    while _end_time > _valid_time:\n",
    "\n",
    "        threads = []        \n",
    "        for i in range(num_th):            \n",
    "            if _end_time <= _valid_time:\n",
    "                break\n",
    "\n",
    "            dt = _valid_time.strftime(\"%Y%m%d\")\n",
    "            t = threading.Thread(target=worker, args=(dt,))\n",
    "            threads.append(t)       \n",
    "            _valid_time = _valid_time.add(days=1)\n",
    "\n",
    "        for t in threads:\n",
    "            t.start()           \n",
    "        for t in threads:\n",
    "            t.join()\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df = pd.concat([Data[k] for k in Data], axis=0)\n",
    "\n",
    "    # Remove columns with more than 90% data as null.\n",
    "    cols_to_delete = df.columns[df.isnull().sum()/len(df) > .90]\n",
    "    df.drop(cols_to_delete, axis = 1, inplace = True)\n",
    "\n",
    "    df = df.sort_values(by=\"valid_time_gmt\")\n",
    "\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"valid_time_gmt\"].astype(int)*1e9) + timedelta(hours=7)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.set_index(\"datetime\")\n",
    "\n",
    "    df = df[['temp', 'rh']]\n",
    "    df['temp'] = df['temp'].astype('float64')\n",
    "    df['rh'] = df['rh'].astype('float64')\n",
    "    return df\n",
    "\n",
    "df_future1 = historical_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f5b2959-a1d5-484d-adb9-48e65bcffbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'en-US', 'transaction_id': '1625388373128:-1242219018', 'version': '1', 'location_id': 'VTBD:9:TH', 'units': 'e', 'expire_time_gmt': 1625388621, 'status_code': 200}\n"
     ]
    }
   ],
   "source": [
    "def forecast_api():\n",
    "    link = 'https://api.weather.com/v1/location/VTBD:9:TH/forecast/hourly/24hour.json?units=e&language=en-US&apiKey=6532d6454b8aa370768e63d6ba5a832e'\n",
    "    res = requests.get(link)\n",
    "    print(json.loads(res.text)['metadata'])\n",
    "    df = pd.DataFrame(json.loads(res.text)['forecasts'])\n",
    "    df['datetime'] = pd.to_datetime(df['fcst_valid_local'].map(lambda x: pendulum.parse(x).to_datetime_string()))\n",
    "    # print(df.columns)\n",
    "    columns = ['datetime', 'temp', 'rh']\n",
    "    df = df[columns]\n",
    "    df = df.set_index('datetime')\n",
    "    df = df.resample('30min').interpolate()\n",
    "    return df\n",
    "\n",
    "df_future2 = forecast_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d6321ed-e6a3-41a5-ba11-d4983cc8913f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>temp</th>\n",
       "      <th>rh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-04 00:00:00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>74.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-04 00:30:00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>74.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-04 01:00:00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>74.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  temp    rh\n",
       "0 2021-07-04 00:00:00 86.00 74.00\n",
       "1 2021-07-04 00:30:00 86.00 74.00\n",
       "2 2021-07-04 01:00:00 86.00 74.00"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concat_then_resample_df(df1, df2):\n",
    "\n",
    "    df = pd.concat([df1,df2])\n",
    "    df = df.resample('30min').interpolate()\n",
    "    today = pendulum.today('Asia/Bangkok').to_date_string()\n",
    "    df= df.loc[today]\n",
    "    yesterday = pendulum.yesterday('Asia/Bangkok').to_date_string()\n",
    "    #df = df.drop(columns = ['rh'], axis =1)\n",
    "    return df.reset_index()\n",
    "\n",
    "X_future = concat_then_resample_df(df_future1, df_future2)\n",
    "X_future.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e6d6cae0-c4d4-48ad-884c-09b40f918875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime    2021-07-04 00:00:00\n",
       "temp                      86.00\n",
       "rh                        74.00\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_future.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a5211-c94e-44d4-ae87-b57625ebac93",
   "metadata": {},
   "source": [
    "### Prepare y_future with np.NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f1a72d6e-0909-4349-995a-517eacf57b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_future = np.empty(len(X_future))\n",
    "y_future[:] = np.NaN\n",
    "y_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d3eac938-3e93-4626-be16-8fceb227987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_future.to_csv (r'x_f.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f4189d5-3fad-419d-9b33-7928da61e06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_automl_target_col'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.target_column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0232cb39-af0c-4d5e-84ad-fd08b150fc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>temp</th>\n",
       "      <th>rh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-04 00:00:00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>74.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-04 00:30:00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>74.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-04 01:00:00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>74.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  temp    rh\n",
       "0 2021-07-04 00:00:00 86.00 74.00\n",
       "1 2021-07-04 00:30:00 86.00 74.00\n",
       "2 2021-07-04 01:00:00 86.00 74.00"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_future['_automl_target_col'] = np.NaN\n",
    "X_future.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d98d8207-7924-4449-ad18-8f38b1d8e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sample = pd.DataFrame({\"datetime\": pd.Series([\"2000-1-1\"], dtype=\"datetime64[ns]\"), \"temp\": pd.Series([0], dtype=\"int64\"), \"rh\": pd.Series([0], dtype=\"int64\")})\n",
    "@input_schema('data', PandasParameterType(input_sample, enforce_shape=False))\n",
    "def run(data):\n",
    "    try:\n",
    "        result = model.forecast(data, y_future)\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        print(json.dumps({\"error\": result}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "32e7bb62-3aaa-4c20-8dd9-567f2c10877b",
   "metadata": {},
   "outputs": [
    {
     "ename": "UntrainedModelException",
     "evalue": "UntrainedModelException:\n\tMessage: UntrainedModelException: No target imputers were found in TimeSeriesTransformer.\n\tInnerException: None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"System\",\n        \"message\": \"UntrainedModelException: No target imputers were found in TimeSeriesTransformer.\",\n        \"target\": \"ForecastingPipelineWrapper\",\n        \"reference_code\": \"ForecastingPipelineWrapper\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUntrainedModelException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-b6bbd553ef67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_future\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_data_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/azureml/automl/runtime/shared/model_wrappers.py\u001b[0m in \u001b[0;36mforecast\u001b[0;34m(self, X_pred, y_pred, forecast_destination, ignore_data_errors)\u001b[0m\n\u001b[1;32m   3152\u001b[0m             X_pred, y_pred, forecast_destination, ignore_data_errors)\n\u001b[1;32m   3153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_recursive_forecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_data_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_data_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3154\u001b[0;31m             \u001b[0mtest_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recursive_forecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_data_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3155\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3156\u001b[0m             \u001b[0mtest_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_regular_forecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_data_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/azureml/automl/runtime/shared/model_wrappers.py\u001b[0m in \u001b[0;36m_recursive_forecast\u001b[0;34m(self, X_copy, ignore_data_errors)\u001b[0m\n\u001b[1;32m   3065\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3067\u001b[0;31m             \u001b[0mX_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recursive_forecast_one_grain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrain_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_data_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3068\u001b[0m             \u001b[0mX_rlt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3069\u001b[0m         \u001b[0mX_fcst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_rlt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/azureml/automl/runtime/shared/model_wrappers.py\u001b[0m in \u001b[0;36m_recursive_forecast_one_grain\u001b[0;34m(self, df_pred, grain, ignore_data_errors)\u001b[0m\n\u001b[1;32m   3024\u001b[0m             \u001b[0;31m# Make a forecast out to the maximum horizon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3026\u001b[0;31m             \u001b[0mX_fcst_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_regular_forecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_pred_expand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_data_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3027\u001b[0m             X_fcst_last[ForecastingPipelineWrapper.TEMP_PRED_COLNAME] = X_fcst_last[\n\u001b[1;32m   3028\u001b[0m                 constants.TimeSeriesInternal.DUMMY_TARGET_COLUMN]\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/azureml/automl/runtime/shared/model_wrappers.py\u001b[0m in \u001b[0;36m_regular_forecast\u001b[0;34m(self, X_copy, ignore_data_errors, is_rolling_forecast)\u001b[0m\n\u001b[1;32m   2951\u001b[0m         \u001b[0;31m# The part of the data frame, for which y_pred is known will be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2952\u001b[0m         \u001b[0;31m# removed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2953\u001b[0;31m         \u001b[0mX_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_missing_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_data_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_rolling_forecast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2954\u001b[0m         \u001b[0mlast_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2955\u001b[0m         \u001b[0;31m# Pre processing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/azureml/automl/runtime/shared/model_wrappers.py\u001b[0m in \u001b[0;36m_infer_missing_data\u001b[0;34m(self, X, ignore_data_errors, ignore_errors_and_warnings)\u001b[0m\n\u001b[1;32m   2894\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mimputer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2895\u001b[0m                         \u001b[0;31m# Should not happen on fitted time series transformer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2896\u001b[0;31m                         raise UntrainedModelException(\n\u001b[0m\u001b[1;32m   2897\u001b[0m                             \u001b[0mForecastingPipelineWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFATAL_NO_TARGET_IMPUTER\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m                             target='ForecastingPipelineWrapper', has_pii=False)\n",
      "\u001b[0;31mUntrainedModelException\u001b[0m: UntrainedModelException:\n\tMessage: UntrainedModelException: No target imputers were found in TimeSeriesTransformer.\n\tInnerException: None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"System\",\n        \"message\": \"UntrainedModelException: No target imputers were found in TimeSeriesTransformer.\",\n        \"target\": \"ForecastingPipelineWrapper\",\n        \"reference_code\": \"ForecastingPipelineWrapper\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "x = model.forecast(X_future, ignore_data_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87b4a59-afc4-4c56-a0b1-1ff05528a109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
