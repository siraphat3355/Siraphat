\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{nhs_2019}
\citation{nhs_2019}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Literature Review}{5}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:literature-review}{{2}{5}{Literature Review}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Fall}{5}{section.2.1}\protected@file@percent }
\newlabel{Fall}{{2.1}{5}{Fall}{section.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Fall Detection}{5}{subsection.2.1.1}\protected@file@percent }
\citation{Alwan_2003}
\citation{alwan_rajendran_kell_mack_dalal_wolfe_felder_2006}
\citation{litvak_zigel_gannot_2008}
\citation{davis_caicedo_langevin_hirth_2011}
\citation{inproceedings}
\citation{shao_wang_song_ilyas_guo_chang_2020}
\citation{liu_jiang_su_benzoni_maxwell_2019}
\citation{clemente_li_valero_song_2020}
\citation{mukherjee2020multisense}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Interest in “Fall Detection” over time from 2004 to present according to Google Trends.}}{6}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:fall_trend}{{2.1}{6}{Interest in “Fall Detection” over time from 2004 to present according to Google Trends}{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Fall detection by using vibration sensors}{6}{subsection.2.1.2}\protected@file@percent }
\citation{schrader_2020}
\citation{schrader_2020}
\citation{oukrich_2019}
\citation{roggen_2010}
\citation{chen_xue_2015}
\citation{reiss_stricker_2012}
\citation{ugolotti_sassi_mordonini_cagnoni_2011}
\citation{abbate_avvenuti_bonatesta_cola_corsini_vecchio_2012}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Summary of literature review for fall detection from floor vibration.}}{7}{table.caption.2}\protected@file@percent }
\newlabel{tab:fall_review}{{2.1}{7}{Summary of literature review for fall detection from floor vibration}{table.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Human Activity}{7}{section.2.2}\protected@file@percent }
\citation{steelconstruction_2016}
\citation{ljunggren2006floor}
\citation{ljunggren2006floor}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Summary of literature review on human activity.}}{8}{table.caption.3}\protected@file@percent }
\newlabel{tab:human_activity}{{2.2}{8}{Summary of literature review on human activity}{table.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Floor Vibrations}{8}{section.2.3}\protected@file@percent }
\citation{p_gavin_2015}
\citation{steelconstruction_2016}
\citation{steelconstruction_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Single degree of freedom system mass-spring model for floor vibration.}}{9}{figure.caption.4}\protected@file@percent }
\newlabel{fig:s_degree}{{2.2}{9}{Single degree of freedom system mass-spring model for floor vibration}{figure.caption.4}{}}
\citation{dash_2020}
\citation{ismail_fawaz_forestier_weber_idoumghar_muller_2019}
\citation{meinard_2007}
\citation{toyoda_sakurai_2012}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Time Series}{10}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Autoregressive (AR)}{10}{subsection.2.4.1}\protected@file@percent }
\citation{dtw_2021}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Time series classification}{11}{subsection.2.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Euclidean maching versus DTW matching.}}{11}{figure.caption.5}\protected@file@percent }
\newlabel{fig:DTW}{{2.3}{11}{Euclidean maching versus DTW matching}{figure.caption.5}{}}
\citation{ismail_fawaz_forestier_weber_idoumghar_muller_2019}
\citation{ismail_fawaz_forestier_weber_idoumghar_muller_2019}
\citation{ismail_fawaz_forestier_weber_idoumghar_muller_2019}
\citation{ismail_fawaz_forestier_weber_idoumghar_muller_2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Convolutional Neural Network (CNN)}{12}{subsection.2.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Convolving on univariate input time series.}}{12}{figure.caption.6}\protected@file@percent }
\newlabel{fig:CNN}{{2.4}{12}{Convolving on univariate input time series}{figure.caption.6}{}}
\citation{vincent10a}
\citation{chollet_2016}
\citation{chollet_2016}
\citation{badr_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Typical temporal convolutional neural network architecture.}}{13}{figure.caption.7}\protected@file@percent }
\newlabel{fig:CNN_ts}{{2.5}{13}{Typical temporal convolutional neural network architecture}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Autoencoders}{13}{section.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces An autocoder workflow.}}{13}{figure.caption.8}\protected@file@percent }
\newlabel{fig:ae}{{2.6}{13}{An autocoder workflow}{figure.caption.8}{}}
\citation{pedamkar_2019}
\citation{pedamkar_2019}
\citation{rajan_2021}
\citation{johns_hopkins_university_2015}
\citation{vincent_larochelle_bengio_manzagol_2008}
\citation{vincent_larochelle_bengio_manzagol_2008}
\citation{vincent10a}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces The autoencoder architecture.}}{14}{figure.caption.9}\protected@file@percent }
\newlabel{fig:ae_architecture}{{2.7}{14}{The autoencoder architecture}{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Visualization of dimensionality reduction using autoencoders.}}{14}{figure.caption.10}\protected@file@percent }
\newlabel{fig:ae_f_reduction}{{2.8}{14}{Visualization of dimensionality reduction using autoencoders}{figure.caption.10}{}}
\citation{rosebrock_2020}
\citation{rosebrock_2020}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces An autoencoder trained on ``clean" images can correct noisy input.}}{15}{figure.caption.11}\protected@file@percent }
\newlabel{fig:ae_2}{{2.9}{15}{An autoencoder trained on ``clean" images can correct noisy input}{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Autoencoders for Anomaly Detection}{15}{subsection.2.5.1}\protected@file@percent }
\citation{pavithrasv_2020}
\citation{pavithrasv_2020}
\citation{roger_2021}
\citation{rocca_2020}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces An autoencoder capable of detecting anomalous events in time series.}}{16}{figure.caption.12}\protected@file@percent }
\newlabel{fig:ae_detection}{{2.10}{16}{An autoencoder capable of detecting anomalous events in time series}{figure.caption.12}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Autoencoder-based anomaly detection \relax }}{16}{algorithm.1}\protected@file@percent }
\newlabel{al:anomaly_detection_algorithm}{{1}{16}{Autoencoder-based anomaly detection \relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Variational Autoencoder}{16}{subsection.2.5.2}\protected@file@percent }
\citation{weng_2018}
\citation{weng_2018}
\citation{agmon_2021}
\citation{goodfellow_pouget_abadie_mirza_xu_warde_farley_ozair_courville_bengio_2014}
\citation{ai_research_innovationhub_2020}
\citation{ai_research_innovationhub_2020}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Architecture of a variational autoencoder.}}{17}{figure.caption.13}\protected@file@percent }
\newlabel{fig:VAE}{{2.11}{17}{Architecture of a variational autoencoder}{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Generative Adversarial Networks (GANs)}{17}{section.2.6}\protected@file@percent }
\citation{tensorflow_2021}
\citation{tensorflow_2021}
\citation{schlegl2017unsupervised}
\citation{schlegl2017unsupervised}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Representation of GAN as a generator and a discriminator.}}{18}{figure.caption.14}\protected@file@percent }
\newlabel{fig:GAN}{{2.12}{18}{Representation of GAN as a generator and a discriminator}{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Training of the generator and discriminator.}}{18}{figure.caption.15}\protected@file@percent }
\newlabel{fig:GAN_training}{{2.13}{18}{Training of the generator and discriminator}{figure.caption.15}{}}
\citation{schlegl2017unsupervised}
\citation{schlegl2017unsupervised}
\citation{donges_2019}
\citation{olah_2015}
\citation{olah_2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Generative Adversarial Networks for Anomaly Detection}{19}{subsection.2.6.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Anomaly detection using AnoGAN.}}{19}{figure.caption.16}\protected@file@percent }
\newlabel{fig:GAN_anomaly}{{2.14}{19}{Anomaly detection using AnoGAN}{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Recurrent Neural Networks (RNNs)}{19}{section.2.7}\protected@file@percent }
\citation{arnx_2019}
\citation{donges_2019}
\citation{donges_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces Recurrent neural network architecture.}}{20}{figure.caption.17}\protected@file@percent }
\newlabel{fig:RNN}{{2.15}{20}{Recurrent neural network architecture}{figure.caption.17}{}}
\citation{olah_2015}
\citation{olah_2015}
\citation{donges_2019}
\citation{olah_2015}
\citation{sirinart_tangruamsub_2017}
\citation{sirinart_tangruamsub_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces The concept of optimization in a feed-forward neural network.}}{21}{figure.caption.18}\protected@file@percent }
\newlabel{fig:bpp}{{2.16}{21}{The concept of optimization in a feed-forward neural network}{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces The repeating module in a standard RNN contains a single layer.}}{21}{figure.caption.19}\protected@file@percent }
\newlabel{fig:RNN_2}{{2.17}{21}{The repeating module in a standard RNN contains a single layer}{figure.caption.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Long Short-Term Memory (LSTM)}{21}{section.2.8}\protected@file@percent }
\citation{sirinart_tangruamsub_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {2.18}{\ignorespaces LSTM structure.}}{22}{figure.caption.20}\protected@file@percent }
\newlabel{fig:LSTM}{{2.18}{22}{LSTM structure}{figure.caption.20}{}}
\citation{olah_2015}
\citation{olah_2015}
\citation{vaswani_shazeer_parmar_uszkoreit_jones_n_gomez_kaiser_polosukhin_2017}
\citation{mishra_verk_fornasier_piciarelli_foresti_2021}
\citation{vaswani_shazeer_parmar_uszkoreit_jones_n_gomez_kaiser_polosukhin_2017}
\citation{vaswani_shazeer_parmar_uszkoreit_jones_n_gomez_kaiser_polosukhin_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {2.19}{\ignorespaces The repeating module in a LSTM contains four interacting layer.}}{24}{figure.caption.21}\protected@file@percent }
\newlabel{fig:LSTM_2}{{2.19}{24}{The repeating module in a LSTM contains four interacting layer}{figure.caption.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}Transformer}{24}{section.2.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.20}{\ignorespaces The transformer architecture.}}{25}{figure.caption.22}\protected@file@percent }
\newlabel{fig:attention}{{2.20}{25}{The transformer architecture}{figure.caption.22}{}}
\citation{james_1890}
\citation{james_1890}
\citation{alammar_2018}
\citation{alammar_2019}
\citation{klingenbrunn_2021}
\citation{alammar_2018}
\citation{alammar_2018}
\@writefile{lof}{\contentsline {figure}{\numberline {2.21}{\ignorespaces Comparison RNNs and Attention.}}{26}{figure.caption.23}\protected@file@percent }
\newlabel{fig:rnnvsattention}{{2.21}{26}{Comparison RNNs and Attention}{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.1}Attention}{26}{subsection.2.9.1}\protected@file@percent }
\citation{alammar_2018}
\citation{alammar_2018}
\citation{alammar_2018}
\citation{alammar_2018}
\citation{alammar_2018}
\citation{alammar_2018}
\@writefile{lof}{\contentsline {figure}{\numberline {2.22}{\ignorespaces Creating the query, key and value vector in a self-attention module.}}{27}{figure.caption.24}\protected@file@percent }
\newlabel{fig:attention_2}{{2.22}{27}{Creating the query, key and value vector in a self-attention module}{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.23}{\ignorespaces Getting a score of how each key matches the query in a self-attention module.}}{27}{figure.caption.25}\protected@file@percent }
\newlabel{fig:attention_3}{{2.23}{27}{Getting a score of how each key matches the query in a self-attention module}{figure.caption.25}{}}
\citation{alammar_2019}
\citation{alammar_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {2.24}{\ignorespaces Summing up the value vectors in a self-attention module.}}{28}{figure.caption.26}\protected@file@percent }
\newlabel{fig:attention_4}{{2.24}{28}{Summing up the value vectors in a self-attention module}{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.25}{\ignorespaces The outcome of the self-attention process.}}{28}{figure.caption.27}\protected@file@percent }
\newlabel{fig:attention_5}{{2.25}{28}{The outcome of the self-attention process}{figure.caption.27}{}}
\citation{tamura_2021}
\citation{tamura_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {2.26}{\ignorespaces Difference between self-attention and masked self-attention.}}{29}{figure.caption.28}\protected@file@percent }
\newlabel{fig:attention_6}{{2.26}{29}{Difference between self-attention and masked self-attention}{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.2}Positional Encoding}{29}{subsection.2.9.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.27}{\ignorespaces Positional encoding of a sequence length of length 50 in a model with a model depth of 256.}}{30}{figure.caption.29}\protected@file@percent }
\newlabel{fig:attention_7}{{2.27}{30}{Positional encoding of a sequence length of length 50 in a model with a model depth of 256}{figure.caption.29}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.10}Notch filter}{30}{section.2.10}\protected@file@percent }
\citation{patel_2019}
\citation{vanderplas_2017}
\citation{vanderplas_2017}
\citation{vanderplas_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {2.28}{\ignorespaces Bode diagram of notch filter}}{31}{figure.caption.30}\protected@file@percent }
\newlabel{fig:notch}{{2.28}{31}{Bode diagram of notch filter}{figure.caption.30}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.11}Principal components analysis}{31}{section.2.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.29}{\ignorespaces The input and output of PCA.}}{32}{figure.caption.31}\protected@file@percent }
\newlabel{fig:pca}{{2.29}{32}{The input and output of PCA}{figure.caption.31}{}}
\@setckpt{8-literatureReview}{
\setcounter{page}{33}
\setcounter{equation}{0}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{11}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{29}
\setcounter{table}{2}
\setcounter{parentequation}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{1}
\setcounter{ALG@line}{8}
\setcounter{ALG@rem}{8}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{8}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{Item}{23}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{34}
\setcounter{lofdepth}{1}
\setcounter{lotdepth}{1}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{BibCnt}{0}
\setcounter{section@level}{0}
\setcounter{maskedRefs}{0}
}
