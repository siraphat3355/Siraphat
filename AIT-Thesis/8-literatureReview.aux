\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{nhs_2019}
\citation{nhs_2019}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Literature Review}{5}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:literature-review}{{2}{5}{Literature Review}{chapter.2}{}}
\@writefile{toc}{\contentsline {paragraph}{}{5}{chapter.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{5}{chapter.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Fall}{5}{section.2.1}\protected@file@percent }
\newlabel{Fall}{{2.1}{5}{Fall}{section.2.1}{}}
\@writefile{toc}{\contentsline {paragraph}{}{5}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Fall Detection}{5}{subsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{5}{subsection.2.1.1}\protected@file@percent }
\citation{Alwan_2003}
\citation{alwan_rajendran_kell_mack_dalal_wolfe_felder_2006}
\citation{litvak_zigel_gannot_2008}
\citation{davis_caicedo_langevin_hirth_2011}
\citation{inproceedings}
\citation{shao_wang_song_ilyas_guo_chang_2020}
\citation{liu_jiang_su_benzoni_maxwell_2019}
\citation{clemente_li_valero_song_2020}
\citation{mukherjee2020multisense}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Interest in “Fall Detection” over time from 2004 to present according to Google Trends.}}{6}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:fall_trend}{{2.1}{6}{Interest in “Fall Detection” over time from 2004 to present according to Google Trends}{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Fall detection by using vibration sensors}{6}{subsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{6}{subsection.2.1.2}\protected@file@percent }
\citation{schrader_2020}
\citation{schrader_2020}
\citation{oukrich_2019}
\citation{roggen_2010}
\citation{chen_xue_2015}
\citation{reiss_stricker_2012}
\citation{ugolotti_sassi_mordonini_cagnoni_2011}
\citation{abbate_avvenuti_bonatesta_cola_corsini_vecchio_2012}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Summary of literature review for fall detection from floor vibration.}}{7}{table.caption.2}\protected@file@percent }
\newlabel{tab:fall_review}{{2.1}{7}{Summary of literature review for fall detection from floor vibration}{table.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Human Activity}{7}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{7}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{7}{section.2.2}\protected@file@percent }
\citation{steelconstruction_2016}
\citation{ljunggren2006floor}
\citation{ljunggren2006floor}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Summary of literature review on human activity.}}{8}{table.caption.3}\protected@file@percent }
\newlabel{tab:human_activity}{{2.2}{8}{Summary of literature review on human activity}{table.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Floor Vibrations}{8}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{8}{section.2.3}\protected@file@percent }
\citation{p_gavin_2015}
\citation{steelconstruction_2016}
\citation{steelconstruction_2016}
\@writefile{toc}{\contentsline {paragraph}{}{9}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{9}{section.2.3}\protected@file@percent }
\citation{dash_2020}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Single degree of freedom system mass-spring model for floor vibration.}}{10}{figure.caption.4}\protected@file@percent }
\newlabel{fig:s_degree}{{2.2}{10}{Single degree of freedom system mass-spring model for floor vibration}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Time Series}{10}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{10}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{10}{section.2.4}\protected@file@percent }
\citation{ismail_fawaz_forestier_weber_idoumghar_muller_2019}
\citation{meinard_2007}
\citation{toyoda_sakurai_2012}
\citation{dtw_2021}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Autoregressive (AR)}{11}{subsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{11}{subsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Time series classification}{11}{subsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{11}{subsection.2.4.2}\protected@file@percent }
\citation{ismail_fawaz_forestier_weber_idoumghar_muller_2019}
\citation{ismail_fawaz_forestier_weber_idoumghar_muller_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Euclidean maching versus DTW matching.}}{12}{figure.caption.5}\protected@file@percent }
\newlabel{fig:DTW}{{2.3}{12}{Euclidean maching versus DTW matching}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {paragraph}{}{12}{figure.caption.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Convolutional Neural Network (CNN)}{12}{subsection.2.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{12}{subsection.2.4.3}\protected@file@percent }
\citation{ismail_fawaz_forestier_weber_idoumghar_muller_2019}
\citation{ismail_fawaz_forestier_weber_idoumghar_muller_2019}
\citation{vincent10a}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Convolving on univariate input time series.}}{13}{figure.caption.6}\protected@file@percent }
\newlabel{fig:CNN}{{2.4}{13}{Convolving on univariate input time series}{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Typical temporal convolutional neural network architecture.}}{13}{figure.caption.7}\protected@file@percent }
\newlabel{fig:CNN_ts}{{2.5}{13}{Typical temporal convolutional neural network architecture}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Autoencoders}{13}{section.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{13}{section.2.5}\protected@file@percent }
\citation{chollet_2016}
\citation{chollet_2016}
\citation{badr_2019}
\citation{pedamkar_2019}
\citation{pedamkar_2019}
\@writefile{toc}{\contentsline {paragraph}{}{14}{section.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces An autocoder workflow.}}{14}{figure.caption.8}\protected@file@percent }
\newlabel{fig:ae}{{2.6}{14}{An autocoder workflow}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {paragraph}{}{14}{figure.caption.8}\protected@file@percent }
\citation{rajan_2021}
\citation{johns_hopkins_university_2015}
\citation{vincent_larochelle_bengio_manzagol_2008}
\citation{vincent_larochelle_bengio_manzagol_2008}
\citation{vincent10a}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces The autoencoder architecture.}}{15}{figure.caption.9}\protected@file@percent }
\newlabel{fig:ae_architecture}{{2.7}{15}{The autoencoder architecture}{figure.caption.9}{}}
\@writefile{toc}{\contentsline {paragraph}{}{15}{figure.caption.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Visualization of dimensionality reduction using autoencoders.}}{15}{figure.caption.10}\protected@file@percent }
\newlabel{fig:ae_f_reduction}{{2.8}{15}{Visualization of dimensionality reduction using autoencoders}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {paragraph}{}{15}{figure.caption.10}\protected@file@percent }
\citation{rosebrock_2020}
\citation{rosebrock_2020}
\citation{pavithrasv_2020}
\citation{pavithrasv_2020}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces An autoencoder trained on ``clean" images can correct noisy input.}}{16}{figure.caption.11}\protected@file@percent }
\newlabel{fig:ae_2}{{2.9}{16}{An autoencoder trained on ``clean" images can correct noisy input}{figure.caption.11}{}}
\@writefile{toc}{\contentsline {paragraph}{}{16}{figure.caption.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Autoencoders for Anomaly Detection}{16}{subsection.2.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{16}{subsection.2.5.1}\protected@file@percent }
\citation{roger_2021}
\citation{rocca_2020}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces An autoencoder capable of detecting anomalous events in time series.}}{17}{figure.caption.12}\protected@file@percent }
\newlabel{fig:ae_detection}{{2.10}{17}{An autoencoder capable of detecting anomalous events in time series}{figure.caption.12}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Autoencoder-based anomaly detection \relax }}{17}{algorithm.1}\protected@file@percent }
\newlabel{al:anomaly_detection_algorithm}{{1}{17}{Autoencoder-based anomaly detection \relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Variational Autoencoder}{17}{subsection.2.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{17}{subsection.2.5.2}\protected@file@percent }
\citation{weng_2018}
\citation{weng_2018}
\citation{agmon_2021}
\citation{goodfellow_pouget_abadie_mirza_xu_warde_farley_ozair_courville_bengio_2014}
\citation{ai_research_innovationhub_2020}
\citation{ai_research_innovationhub_2020}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Architecture of a variational autoencoder.}}{18}{figure.caption.13}\protected@file@percent }
\newlabel{fig:VAE}{{2.11}{18}{Architecture of a variational autoencoder}{figure.caption.13}{}}
\@writefile{toc}{\contentsline {paragraph}{}{18}{figure.caption.13}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Generative Adversarial Networks (GANs)}{18}{section.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{18}{section.2.6}\protected@file@percent }
\citation{tensorflow_2021}
\citation{tensorflow_2021}
\citation{schlegl2017unsupervised}
\citation{schlegl2017unsupervised}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Representation of GAN as a generator and a discriminator.}}{19}{figure.caption.14}\protected@file@percent }
\newlabel{fig:GAN}{{2.12}{19}{Representation of GAN as a generator and a discriminator}{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Training of the generator and discriminator.}}{19}{figure.caption.15}\protected@file@percent }
\newlabel{fig:GAN_training}{{2.13}{19}{Training of the generator and discriminator}{figure.caption.15}{}}
\citation{schlegl2017unsupervised}
\citation{schlegl2017unsupervised}
\citation{donges_2019}
\citation{olah_2015}
\citation{olah_2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Generative Adversarial Networks for Anomaly Detection}{20}{subsection.2.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{20}{subsection.2.6.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Anomaly detection using AnoGAN.}}{20}{figure.caption.16}\protected@file@percent }
\newlabel{fig:GAN_anomaly}{{2.14}{20}{Anomaly detection using AnoGAN}{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Recurrent Neural Networks (RNNs)}{20}{section.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{20}{section.2.7}\protected@file@percent }
\citation{arnx_2019}
\citation{donges_2019}
\citation{donges_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces Recurrent neural network architecture.}}{21}{figure.caption.17}\protected@file@percent }
\newlabel{fig:RNN}{{2.15}{21}{Recurrent neural network architecture}{figure.caption.17}{}}
\@writefile{toc}{\contentsline {paragraph}{}{21}{figure.caption.17}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{21}{figure.caption.17}\protected@file@percent }
\citation{olah_2015}
\citation{olah_2015}
\citation{donges_2019}
\citation{olah_2015}
\citation{sirinart_tangruamsub_2017}
\citation{sirinart_tangruamsub_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces The concept of optimization in a feed-forward neural network.}}{22}{figure.caption.18}\protected@file@percent }
\newlabel{fig:bpp}{{2.16}{22}{The concept of optimization in a feed-forward neural network}{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces The repeating module in a standard RNN contains a single layer.}}{22}{figure.caption.19}\protected@file@percent }
\newlabel{fig:RNN_2}{{2.17}{22}{The repeating module in a standard RNN contains a single layer}{figure.caption.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Long Short-Term Memory (LSTM)}{22}{section.2.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{22}{section.2.8}\protected@file@percent }
\citation{sirinart_tangruamsub_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {2.18}{\ignorespaces LSTM structure.}}{23}{figure.caption.20}\protected@file@percent }
\newlabel{fig:LSTM}{{2.18}{23}{LSTM structure}{figure.caption.20}{}}
\@writefile{toc}{\contentsline {paragraph}{}{23}{figure.caption.20}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{23}{figure.caption.20}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{23}{figure.caption.20}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{24}{figure.caption.20}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{24}{figure.caption.20}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{24}{figure.caption.20}\protected@file@percent }
\citation{olah_2015}
\citation{olah_2015}
\citation{vaswani_shazeer_parmar_uszkoreit_jones_n_gomez_kaiser_polosukhin_2017}
\citation{mishra_verk_fornasier_piciarelli_foresti_2021}
\citation{vaswani_shazeer_parmar_uszkoreit_jones_n_gomez_kaiser_polosukhin_2017}
\citation{vaswani_shazeer_parmar_uszkoreit_jones_n_gomez_kaiser_polosukhin_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {2.19}{\ignorespaces The repeating module in a LSTM contains four interacting layer.}}{25}{figure.caption.21}\protected@file@percent }
\newlabel{fig:LSTM_2}{{2.19}{25}{The repeating module in a LSTM contains four interacting layer}{figure.caption.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}Transformer}{25}{section.2.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{25}{section.2.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.20}{\ignorespaces The transformer architecture.}}{26}{figure.caption.22}\protected@file@percent }
\newlabel{fig:attention}{{2.20}{26}{The transformer architecture}{figure.caption.22}{}}
\@writefile{toc}{\contentsline {paragraph}{}{26}{figure.caption.22}\protected@file@percent }
\citation{james_1890}
\citation{james_1890}
\citation{alammar_2018}
\citation{alammar_2019}
\citation{klingenbrunn_2021}
\citation{alammar_2018}
\citation{alammar_2018}
\@writefile{lof}{\contentsline {figure}{\numberline {2.21}{\ignorespaces Comparison RNNs and Attention.}}{27}{figure.caption.23}\protected@file@percent }
\newlabel{fig:rnnvsattention}{{2.21}{27}{Comparison RNNs and Attention}{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.1}Attention}{27}{subsection.2.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{27}{subsection.2.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{27}{Item.19}\protected@file@percent }
\citation{alammar_2018}
\citation{alammar_2018}
\citation{alammar_2018}
\citation{alammar_2018}
\citation{alammar_2018}
\citation{alammar_2018}
\@writefile{lof}{\contentsline {figure}{\numberline {2.22}{\ignorespaces Creating the query, key and value vector in a self-attention module.}}{28}{figure.caption.24}\protected@file@percent }
\newlabel{fig:attention_2}{{2.22}{28}{Creating the query, key and value vector in a self-attention module}{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.23}{\ignorespaces Getting a score of how each key matches the query in a self-attention module.}}{28}{figure.caption.25}\protected@file@percent }
\newlabel{fig:attention_3}{{2.23}{28}{Getting a score of how each key matches the query in a self-attention module}{figure.caption.25}{}}
\citation{alammar_2019}
\citation{alammar_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {2.24}{\ignorespaces Summing up the value vectors in a self-attention module.}}{29}{figure.caption.26}\protected@file@percent }
\newlabel{fig:attention_4}{{2.24}{29}{Summing up the value vectors in a self-attention module}{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.25}{\ignorespaces The outcome of the self-attention process.}}{29}{figure.caption.27}\protected@file@percent }
\newlabel{fig:attention_5}{{2.25}{29}{The outcome of the self-attention process}{figure.caption.27}{}}
\@writefile{toc}{\contentsline {paragraph}{}{29}{figure.caption.27}\protected@file@percent }
\citation{tamura_2021}
\citation{tamura_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {2.26}{\ignorespaces Difference between self-attention and masked self-attention.}}{30}{figure.caption.28}\protected@file@percent }
\newlabel{fig:attention_6}{{2.26}{30}{Difference between self-attention and masked self-attention}{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.2}Positional Encoding}{30}{subsection.2.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{30}{subsection.2.9.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.27}{\ignorespaces Positional encoding of a sequence length of length 50 in a model with a model depth of 256.}}{31}{figure.caption.29}\protected@file@percent }
\newlabel{fig:attention_7}{{2.27}{31}{Positional encoding of a sequence length of length 50 in a model with a model depth of 256}{figure.caption.29}{}}
\@setckpt{8-literatureReview}{
\setcounter{page}{32}
\setcounter{equation}{0}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{9}
\setcounter{subsection}{2}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{27}
\setcounter{table}{2}
\setcounter{parentequation}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{1}
\setcounter{ALG@line}{8}
\setcounter{ALG@rem}{8}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{8}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{Item}{23}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{30}
\setcounter{lofdepth}{1}
\setcounter{lotdepth}{1}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{BibCnt}{0}
\setcounter{section@level}{0}
\setcounter{maskedRefs}{0}
}
